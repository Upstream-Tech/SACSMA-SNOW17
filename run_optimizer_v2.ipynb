{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "from pathlib import Path\n",
    "from ruamel.yaml import YAML\n",
    "from os import path\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "import spotpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CAMELS imports\n",
    "import model.camels_utilities as camels\n",
    "from optimizer.optimizer import spotpy_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run directory\n",
    "run_dir = Path('/home/gsnearing/projects/lstm_based_hydrology/extreme_year_runs/')\n",
    "out_dir = Path('./results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 192 experiments.\n"
     ]
    }
   ],
   "source": [
    "# load config files\n",
    "config_files = list(run_dir.glob('**/config.yml'))\n",
    "print(f'There are {len(config_files)} experiments.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer hypers\n",
    "max_model_runs = 1e5 # 1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Need at least two processes for parallelization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b1e11a1eed96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# configure optimizer hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         sampler=spotpy.algorithms.sceua(optimizer, \n\u001b[0m\u001b[1;32m     41\u001b[0m                                         \u001b[0mdbname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SCE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                                         \u001b[0mdbformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ram'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sacsma/lib/python3.8/site-packages/spotpy/algorithms/sceua.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimization_direction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'minimize'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'algorithm_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Shuffled Complex Evolution (SCE-UA) algorithm'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msceua\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sacsma/lib/python3.8/site-packages/spotpy/algorithms/_algorithm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, spot_setup, dbname, dbformat, dbinit, dbappend, parallel, save_sim, breakpoint, backup_every_rep, save_threshold, db_precision, sim_timeout, random_state, optimization_direction, algorithm_name)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;31m# to other functions. This is introduced for sceua to differentiate between burn in and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;31m# the normal work on the chains\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mForEach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# method \"save\" needs to know whether objective function result is list or float, default is float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/sacsma/lib/python3.8/site-packages/spotpy/parallel/mpi.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGet_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Need at least two processes for parallelization'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGet_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Need at least two processes for parallelization"
     ]
    }
   ],
   "source": [
    "# loop over experiments\n",
    "for f, config_file in enumerate(config_files):\n",
    "    \n",
    "    # read config file\n",
    "    with config_file.open('r') as fp:\n",
    "        yaml = YAML(typ=\"safe\")\n",
    "        yaml.allow_duplicate_keys = True\n",
    "        cfg = yaml.load(fp)  \n",
    "    \n",
    "    # extract training dates\n",
    "    with open(cfg['train_dates_file'], 'rb') as f:\n",
    "        train_dates = pkl.load(f)\n",
    "\n",
    "    # list all basins in this experiment    \n",
    "    basins = list(train_dates['start_dates'].keys())\n",
    "    assert len(basins) == 531\n",
    "\n",
    "    # loop over basins\n",
    "    for basin in basins:\n",
    "\n",
    "        # training dates for this basin\n",
    "        sd = train_dates['start_dates'][basin]\n",
    "        ed = train_dates['end_dates'][basin]\n",
    "        obj_fun_dates = pd.DataFrame(list(chain.from_iterable(pd.date_range(sdi, edi) for sdi, edi in zip(sd, ed))), columns = ('train_dates',))\n",
    "\n",
    "        # load data\n",
    "        mask_dates = obj_fun_dates['train_dates']\n",
    "        attributes = camels.load_basin_attributes(basin)\n",
    "        forcings, area = camels.load_forcings(basin)\n",
    "        observations = camels.load_usgs(basin, area)\n",
    "\n",
    "        # set up optimizer\n",
    "        optimizer = spotpy_setup(forcings=forcings,\n",
    "                                 observations=observations['QObs'],\n",
    "                                 latitude=attributes['gauge_lat'],\n",
    "                                 elevation=attributes['elev_mean'],\n",
    "                                 mask_dates=mask_dates)\n",
    "\n",
    "        # configure optimizer hyperparameters\n",
    "        sampler=spotpy.algorithms.sceua(optimizer, \n",
    "                                        dbname='SCE', \n",
    "                                        dbformat='ram',\n",
    "                                        parallel='mpi',\n",
    "                                        save_sim=True) # False\n",
    "\n",
    "        # run it\n",
    "        sampler.sample(repetitions=max_model_runs, ngs=len(optimizer.optimized_parameter_names))\n",
    "\n",
    "        # get best parameters\n",
    "        results = sampler.getdata()\n",
    "        best_parameters = spotpy.analyser.get_best_parameterset(results,maximize=False)\n",
    "        best_parameters_df = pd.DataFrame(best_parameters)\n",
    "        for key in best_parameters_df.keys():\n",
    "            new_key = key.split('par')[-1]\n",
    "            best_parameters_df = best_parameters_df.rename(columns={key: new_key})\n",
    "        best_parameters_series = best_parameters_df.transpose()[0]\n",
    "\n",
    "        # get simulation with best parameters\n",
    "        parm_vector = best_parameters_series.loc[optimizer.optimized_parameter_names].values\n",
    "        sim = optimizer.simulation(parm_vector)\n",
    "\n",
    "        # save output\n",
    "        outfile = out_dir / f\"{str(config_file).split('/')[-2][:-10]}_{basin}.pkl\"\n",
    "        with open(outfile, 'wb') as f:\n",
    "            pkl.dump([best_parameters_series, sim], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
