{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command is executed twice for interactive plotting in Jupyter notebook\n",
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import h5py\n",
    "import os\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path('/home/gsnearing/projects/lstm_based_hydrology/') # lstm codebase\n",
    "config_file = working_dir / 'configs/extreme_years.yml' # config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(working_dir))\n",
    "from codebase.config import read_config\n",
    "from codebase.data.utils import load_basin_file\n",
    "from codebase.data.climateindices import precalculate_dyn_climate_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of train and test years\n",
    "n_train_years = 9\n",
    "n_test_years = 3\n",
    "n_skip_years = [0,4,8,12]\n",
    "holdout_types = ['low', 'median', 'high']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load configuration file for this run\n",
    "cfg = read_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 531 basins.\n"
     ]
    }
   ],
   "source": [
    "# basin lists\n",
    "basins = load_basin_file(cfg['train_basin_file'])\n",
    "nBasins = len(basins)\n",
    "print(f'There are {nBasins} basins.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Dynamic Climate Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 531/531 [01:50<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precalculated features successfully stored at /home/gsnearing/projects/lstm_based_hydrology/data/dyn_climate_indices_daymet_531basins_365lookback.p\n"
     ]
    }
   ],
   "source": [
    "# calculate all climate indexes\n",
    "climate_indexes = precalculate_dyn_climate_indices(data_dir=cfg['data_dir'], \n",
    "                                                   basin_file=cfg['train_basin_file'], \n",
    "                                                   window_length=cfg['seq_length'],\n",
    "                                                   forcings=cfg['forcings'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leading nans\n",
    "for basin in basins:\n",
    "    climate_indexes[basin] = climate_indexes[basin].iloc[364*4:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Climate Index are:  ['p_mean_dyn', 'pet_mean_dyn', 'aridity_dyn', 't_mean_dyn', 'frac_snow_dyn', 'high_prec_freq_dyn', 'high_prec_dur_dyn', 'low_prec_freq_dyn', 'low_prec_dur_dyn']\n"
     ]
    }
   ],
   "source": [
    "# dimensions\n",
    "assert nBasins == len(climate_indexes) # basins\n",
    "nTimes, nClimate = climate_indexes[basins[0]].shape\n",
    "climate_index_names = list(climate_indexes[basins[0]].columns)\n",
    "print('Climate Index are: ', climate_index_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract timestamps\n",
    "dates = climate_indexes[basins[0]].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "climate_indexes_np = np.full([nTimes, nBasins, nClimate], np.nan)\n",
    "for b, basin in enumerate(basins):\n",
    "    climate_indexes_np[:,b,:] = climate_indexes[basin].values\n",
    "assert np.all(~np.isnan(climate_indexes_np))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Extreme Years in Each Basin by Each Climate Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 water years.\n"
     ]
    }
   ],
   "source": [
    "# find water years\n",
    "start_mask = ((dates.month == 10) & (dates.day == 1))\n",
    "water_year_start_dexes = np.where(start_mask)[0][:-1]\n",
    "end_mask = ((dates.month == 9) & (dates.day == 30))\n",
    "water_year_end_dexes = np.where(end_mask)[0][1:]\n",
    "\n",
    "# list water years\n",
    "years = np.unique(dates[start_mask].year)\n",
    "years = years[:-1]\n",
    "nYears = len(years)\n",
    "print(f'There are {nYears} water years.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull and sort water years from climate indexes\n",
    "climate_water_years = climate_indexes_np[water_year_start_dexes,:,:]\n",
    "sorted_climate_water_years_indexes = np.argsort(climate_water_years, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, '01022500')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-6c35d058d384>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclimate_water_years\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbasin\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0myear_start_dexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclimate_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbasin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclimate_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbasin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mclimate_water_years\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbasin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myear_start_dexes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, '01022500')"
     ]
    }
   ],
   "source": [
    "# save climate indexes for analysis script\n",
    "climate_water_years = {}\n",
    "for basin in enumerate(basins):\n",
    "    year_start_dexes = np.where((climate_indexes[basin].index.month == 1) & (climate_indexes[basin].index.day == 1))\n",
    "    climate_water_years[basin].iloc[year_start_dexes]\n",
    "\n",
    "file = 'notebook_env_saves/extreme_year_climate_indexes.pkl'\n",
    "with open(file, 'wb') as f:\n",
    "    pkl.dump(climate_water_years, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Dates Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_years(original_list, remove_first_n, skip_n):\n",
    "    remove_list = []\n",
    "    for i in range(remove_first_n):\n",
    "        remove_list.append(original_list[i])\n",
    "        remove_list.append(original_list[i]+1)\n",
    "        remove_list.append(original_list[i]-1)\n",
    "    pruned_list = [ele for ele in original_list if ele not in remove_list] \n",
    "    return pruned_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(idx, htype, skip):\n",
    "\n",
    "    if htype == 'low':\n",
    "        test = idx[:n_test_years]\n",
    "        pruned_list = filter_years(idx, n_test_years, skip)\n",
    "        train = pruned_list[skip:skip+n_train_years]\n",
    "    \n",
    "    elif htype =='high':\n",
    "        test = idx[-n_test_years:]\n",
    "        idx.reverse()\n",
    "        pruned_list = filter_years(idx, n_test_years, skip)\n",
    "        train = pruned_list[skip:skip+n_train_years]\n",
    "\n",
    "    elif htype == 'median':\n",
    "        sdex = int(np.ceil((len(idx) - n_test_years) / 2))\n",
    "        edex = int(np.floor((len(idx) - n_test_years) / 2))\n",
    "        test = idx[sdex:-edex]\n",
    "        train = test.copy()\n",
    "        for step in range(len(idx)):\n",
    "            try:\n",
    "                train.append(idx[sdex-step])\n",
    "                train.append(idx[edex+step+1])\n",
    "            except:\n",
    "                pass\n",
    "        pruned_list = filter_years(train, n_test_years, skip)\n",
    "        train = pruned_list[skip:skip+n_train_years]\n",
    "\n",
    "    return test, train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dates\n",
    "test_dates = {}\n",
    "train_dates = {}\n",
    "for i, index in enumerate(tqdm(climate_index_names)):\n",
    "    for htype in holdout_types:\n",
    "        for skip in n_skip_years:\n",
    "            \n",
    "            test_dates[(index,htype,skip)] = {}\n",
    "            train_dates[(index,htype,skip)] = {}\n",
    "\n",
    "            test_dates[(index,htype,skip)]['start_dates'] = {}\n",
    "            test_dates[(index,htype,skip)]['end_dates'] = {}\n",
    "            train_dates[(index,htype,skip)]['start_dates'] = {}\n",
    "            train_dates[(index,htype,skip)]['end_dates'] = {}\n",
    "            \n",
    "            for b, basin in enumerate(basins):\n",
    "                test_dex, train_dex = train_test_split(list(sorted_climate_water_years_indexes[:,b,i]), htype, skip)\n",
    "                \n",
    "                test_dates[(index,htype,skip)]['start_dates'][basin] = dates[water_year_start_dexes[test_dex]]\n",
    "                test_dates[(index,htype,skip)]['end_dates'][basin] = dates[water_year_end_dexes[test_dex]]\n",
    "                \n",
    "                train_dates[(index,htype,skip)]['start_dates'][basin] = dates[water_year_start_dexes[train_dex]]\n",
    "                train_dates[(index,htype,skip)]['end_dates'][basin] = dates[water_year_end_dexes[train_dex]]\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train/Test Dates Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, index in enumerate(tqdm(climate_index_names)):\n",
    "    for htype in holdout_types:\n",
    "        for skip in n_skip_years:\n",
    "            test_fname = Path(f'{working_dir}/extreme_year_dates/test_{index}_{htype}_{skip}.pkl')\n",
    "            with open(test_fname, 'wb') as f:\n",
    "                pkl.dump(test_dates[(index,htype,skip)], f)\n",
    "            \n",
    "            train_fname = Path(f'{working_dir}/extreme_year_dates/train_{index}_{htype}_{skip}.pkl')\n",
    "            with open(train_fname, 'wb') as f:\n",
    "                pkl.dump(train_dates[(index,htype,skip)], f)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates[(index,htype,skip)]['start_dates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Config Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_config_file = Path(f'{working_dir}/configs/extreme_years.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_climate_indexes = ['p_mean_dyn', 'aridity_dyn']\n",
    "for index in use_climate_indexes:\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of ensembles\n",
    "num_seeds = 8\n",
    "first_seed = 200\n",
    "seeds = list(range(first_seed, first_seed + num_seeds))\n",
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cretate training files for high-end of climate indexes\n",
    "for index in use_climate_indexes:\n",
    "    for htype in holdout_types:\n",
    "        for skip in n_skip_years:\n",
    "            for seed in seeds:\n",
    "\n",
    "                # read basefile\n",
    "                with open(base_config_file, 'r') as file :\n",
    "                    filedata = file.read()\n",
    "\n",
    "                # replace experiment name\n",
    "                exp_name = f'{index}_{htype}_{skip}_{seed}'\n",
    "                filedata = filedata.replace('extreme_years', exp_name)\n",
    "\n",
    "                # replace train dates file\n",
    "                train_dates_fname = f'train_{index}_{htype}_{skip}.pkl'\n",
    "                filedata = filedata.replace('train_high_p_mean_dyn_0.pkl', train_dates_fname)\n",
    "\n",
    "                # replace test dates file\n",
    "                test_dates_fname = f'test_{index}_{htype}_{skip}.pkl'\n",
    "                filedata = filedata.replace('test_high_p_mean_dyn_0.pkl', test_dates_fname)\n",
    "\n",
    "                # replace random seed\n",
    "                filedata = filedata.replace('seed: 100', f'seed: {seed}')\n",
    "\n",
    "                # write to new config file\n",
    "                new_config_file = Path(f'{working_dir}/extreme_year_configs/{exp_name}.yml')\n",
    "                with open(new_config_file, 'w') as file:\n",
    "                    file.write(filedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
